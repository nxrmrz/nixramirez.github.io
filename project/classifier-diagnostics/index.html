<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.7.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Nicole Ramirez">

  
  
  
    
  
  <meta name="description" content="How do we make sense of different model metrics?">

  
  <link rel="alternate" hreflang="en-us" href="https://nixramirez.github.io/project/classifier-diagnostics/">

  


  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  




  


  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="https://nixramirez.github.io/project/classifier-diagnostics/">

  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Hello, World">
  <meta property="og:url" content="https://nixramirez.github.io/project/classifier-diagnostics/">
  <meta property="og:title" content="Assessing Classification Models | Hello, World">
  <meta property="og:description" content="How do we make sense of different model metrics?"><meta property="og:image" content="https://nixramirez.github.io/project/classifier-diagnostics/featured.jpg">
  <meta property="twitter:image" content="https://nixramirez.github.io/project/classifier-diagnostics/featured.jpg"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2020-06-08T00:00:00&#43;00:00">
    
    <meta property="article:modified_time" content="2020-06-08T00:00:00&#43;00:00">
  

  


    











<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://nixramirez.github.io/project/classifier-diagnostics/"
  },
  "headline": "Assessing Classification Models",
  
  "image": [
    "https://nixramirez.github.io/project/classifier-diagnostics/featured.jpg"
  ],
  
  "datePublished": "2020-06-08T00:00:00Z",
  "dateModified": "2020-06-08T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Nicole Ramirez"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Hello, World",
    "logo": {
      "@type": "ImageObject",
      "url": "img/https://nixramirez.github.io/"
    }
  },
  "description": "How do we make sense of different model metrics?"
}
</script>

  

  


  


  





  <title>Assessing Classification Models | Hello, World</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  







<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Hello, World</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Hello, World</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#experience"><span>Experience</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Projects</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      <li class="nav-item">
        <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
      </li>
      

      

    </ul>

  </div>
</nav>


  <article class="article article-project">

  




















  
  
    
  


<div class="article-container pt-3">
  <h1>Assessing Classification Models</h1>

  

  


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    Jun 8, 2020
  </span>
  

  

  

  
  
  

  
  

</div>

  














</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 720px; max-height: 720px;">
  <div style="position: relative">
    <img src="/project/classifier-diagnostics/featured_hue11f07d64ab38b9c97b497fc6860c53e_27131_720x0_resize_q90_lanczos.jpg" alt="" class="featured-image">
    
  </div>
</div>



  <div class="article-container">

    <div class="article-style">
      <p><strong>TL;DR:</strong> In applied machine learning, models are often optimised for their accuracy in predicting a target. When the target is quantitative, measures like the R^2 value and the Root Mean Squared Error (RMSE) etc., help in quantifying this accuracy. When the target is qualitative, metrics like Accuracy, Precision, Recall and several others are used. We term these measures &lsquo;classification metrics&rsquo; for the sake of this blog post.</p>
<p>In this post, I explain classification metrics and provide python code to calculate them. I also produce a report including them that can be easily saved to a file for later use.</p>
<p>Say you&rsquo;ve run your data through a classifier, and the classifier has predicted labels for your data. To judge how accurate those predictions are, you can evaluate them by the metrics explained below</p>
<h3 id="section-1-classification-metrics">Section 1: Classification Metrics</h3>
<p>The metrics covered by this post is as follows:</p>
<ul>
<li><strong>Accuracy</strong> - What proportion of sentences were correctly classified (i.e. as positive, negative, neutral)?</li>
<li><strong>Precision</strong> - Answers the q: What proportion of <em>predicted</em> positives were actual positives? The polar opposite for this is specificity:
<ul>
<li><strong>Specificity</strong> - Answers the q: What proportion of <em>predicted</em> negatives were actual negatives?</li>
</ul>
</li>
<li><strong>Recall/Sensitivity</strong> - Answers the q: What proportion of <em>actual</em> positives were predicted positive?</li>
<li><strong>F-1 Score</strong> - The harmonic mean of a classifier&rsquo;s precision and recall scores</li>
</ul>
<p>Generally, when someone mentions the last 3 metrics above, without a prefix, they mean them to be the <em>macro-precision</em>, <em>macro-recall</em>, and <em>macro-F1</em>, These metrics come in two other flavours however, the micro- and the weighted. Let&rsquo;s take the example of the precision score (but the exact same descriptions can be said for recall and the F-1 score). Whilst the macro precision is simply the average of the precision scores calculated for each class, the weighted precision weights this score by the number of examples of that class before averaging across classes. This is why macro precision is a better metric for balanced data-sets weighted precision is better for imbalanced ones. Micro precision is more involved than both, and is explained later on.</p>
<p>The above metrics can be calculated from a <strong>confusion matrix</strong> which is a 2D matrix showing the predicted and actual counts of a target category, therefore showing the distribution of True Positives (TPs), False Positives (FPs), True Negatives (TNs), and False Negatives (FNs) in your data.</p>
<p>As we see in Section 1.1 below, the equations of the above metrics require knowledge of the TP/FPs and TN/FNs. Calculating the above metrics by hand therefore requires a confusion matrix to be made beforehand.</p>
<h4 id="section-11-diving-deeper-into-the-metrics">Section 1.1: Diving Deeper into the Metrics</h4>
<p>Let&rsquo;s display a confusion matrix for a binary classification (i.e. 2 classes for the target) problem to intuitively get a grasp of its contents.</p>
<p><img src="CM1.png" alt="Confusion Matrix"></p>
<p>The goal for a classifier is to increase TP/TNs while reducing misclassification, or the number of FP/FNs</p>
<p>Knowing the above, our metrics can be represented as the following equations:
$$
Accuracy = \frac{TP + TN}{FP + FN + TP + TN}
$$</p>
<p>$$
Precision = \frac{TP}{TP + FP}
$$</p>
<p>$$
Recall = \frac{TP}{TP + FN}
$$</p>
<p>$$
F_1= \frac{2}{\frac{1}{Precision} \times \frac{1}{Recall}} = 2 \times \frac{Recall \times Precision}{Recall + Precision}
$$</p>
<h4 id="section-12-diving-deeper-into-various-flavours-of-precision">Section 1.2: Diving Deeper into various flavours of Precision</h4>
<p>Shown above is the equation for the precision score of <strong>one class</strong>.</p>
<p>The macro and weighted precision scores for a binary classification (i.e. with 2 classes) can be represented as:</p>
<p>$$
Macro Precision= \frac{Precision_{class1} + Precision_{class2}}{2}
$$</p>
<p>$$
Weighted Precision= \frac{(Precision_{class1} \times c_1) + (Precision_{class2} \times c_2)}{c_1 + c_2}
$$</p>
<p>where $c_1$ and $c_2$ are the number of examples in classes $1$ and $2$</p>
<p>Note that if we replace <code>Precision</code> above with <code>F-1 score</code> or <code>Recall</code>, the formulas would still work!</p>
<p>To calculate micro precision, instead of taking measurements of precision <strong>for each class</strong> (i.e. taking TPs and FPs for each class), we compute TPs and FPs out of the <strong>total pool</strong> of examples.</p>
<p>Take the confusion matrix below for another binary classification problem, classifying photos of a cat or a dog.
<img src="confusion_matrix.png" alt="confusion matrix 2"></p>
<p>We calculate the TP and FP out of the total number of examples as follows:
<img src="TP+FP.png" alt="TP+FP"></p>
<p>And therefore our micro precision is:
<img src="microprecision.png" alt="microprecision"></p>
<h4 id="section-13-the-rocauc-scores">Section 1.3: The ROC/AUC scores</h4>
<p>In a later blog post, we&rsquo;ll explore two additional metrics briefly described below, as they are derived simultaneously while training a machine learning model.</p>
<ul>
<li>ROC curve - Shows how changing the classification threshold changes the True Positive Rate and False Positive Rate. The classification threshold can be visually represented best by the diagram below:</li>
<li>AUC - The area under the ROC curve. A high AUC value, associated with a ROC curve occupying the upper left quadrant is ideal and indicates a good classifier (i.e. because its True Positive Rate is high, whilst its False Positive Rate is low)</li>
</ul>
<p><img src="roc-curve-v2.png" alt="ROC-AUC curves"></p>
<h4 id="what-metric-do-we-choose-to-evaluate-our-classifier-by">What metric do we choose to evaluate our classifier by?</h4>
<p>It ultimately depends on your research question. If you&rsquo;re classifying who has diabetes from a patient pool, for example, you&rsquo;d want recall to be high. If you&rsquo;re recommending movies to a user, you&rsquo;d want the user to like the movies you recommended, so you&rsquo;d want precision to be high. Overall, with a balanced data-set, you&rsquo;d want accuracy to be high. With an un-balanced data-set, you&rsquo;d want the weighted F1-score to be high.</p>
<h3 id="section-2-code">Section 2: Code</h3>
<pre><code class="language-python">#first we import necessary packages
from sklearn import metrics
import pandas as pd
import os
import numpy as np
</code></pre>
<p>After training a classifier to generate predictions, we apply the diagnostic metrics above, often comparing predictions to the true labels.</p>
<p>In the data-frame below, we have a column housing true labels (i.e. <code>sentiment</code>), and one housing predictions (i.e. <code>predictions</code>)</p>
<pre><code class="language-python">#insert the data-set you'd want to read
df = pd.read_csv('predictions_starship_albert_epoch10.csv')
</code></pre>
<pre><code class="language-python">sentiment_to_categories_dict = {
    2: 'positive',
    1: 'neutral',
    0: 'negative'
}
</code></pre>
<pre><code class="language-python">df.sentiment = df.sentiment.apply(lambda sentiment: sentiment_to_categories_dict[sentiment])
</code></pre>
<pre><code class="language-python">df.head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>entry</th>
      <th>sentiment</th>
      <th>predictions</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>Up early ferry to Rangitoto walked up snack at...</td>
      <td>positive</td>
      <td>neutral</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>P home on time. Nap then food shop girls over ...</td>
      <td>neutral</td>
      <td>negative</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>Morning nap did not get up until late shower t...</td>
      <td>neutral</td>
      <td>neutral</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>N. Slept well but tired. Busy board at start b...</td>
      <td>neutral</td>
      <td>neutral</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>N. Slept well woken by post. Slow but steady n...</td>
      <td>neutral</td>
      <td>neutral</td>
    </tr>
  </tbody>
</table>
</div>
<p>We store the predictions and true labels on separate vectors</p>
<pre><code class="language-python">#True values (actual)
y_true = df['sentiment']

#predicted values (from model output)
y_pred = df['predictions']
</code></pre>
<p>We then create row and column labels to append to our confusion matrix later on</p>
<pre><code class="language-python">#get row and column labels for confusion matrix

#get unique row labels
row_labels = np.unique(y_true)

#get column labels
column_labels = [label + &quot;_predicted&quot; for label in row_labels]
</code></pre>
<p>Here we create a confusion matrix, passing in the row and column labels we create above</p>
<pre><code class="language-python">#create a confusion matrix object and display it (with labels)
c_m = pd.DataFrame(metrics.confusion_matrix(y_true,y_pred), index=row_labels, columns=column_labels)
</code></pre>
<p>We display the confusion matrix:</p>
<pre><code class="language-python">c_m
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>negative_predicted</th>
      <th>neutral_predicted</th>
      <th>positive_predicted</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>negative</th>
      <td>6</td>
      <td>26</td>
      <td>3</td>
    </tr>
    <tr>
      <th>neutral</th>
      <td>12</td>
      <td>40</td>
      <td>10</td>
    </tr>
    <tr>
      <th>positive</th>
      <td>8</td>
      <td>21</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>
<p>&hellip;as a data-frame&hellip;with all of the other metrics mentioned above:</p>
<pre><code class="language-python">#display all diagnostics as a data-frame, save results to a variable too
confusion_matrix = pd.DataFrame(metrics.classification_report(y_true,y_pred, digits=3, output_dict=True))
confusion_matrix
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>negative</th>
      <th>neutral</th>
      <th>positive</th>
      <th>accuracy</th>
      <th>macro avg</th>
      <th>weighted avg</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>precision</th>
      <td>0.230769</td>
      <td>0.459770</td>
      <td>0.133333</td>
      <td>0.375</td>
      <td>0.274624</td>
      <td>0.318094</td>
    </tr>
    <tr>
      <th>recall</th>
      <td>0.171429</td>
      <td>0.645161</td>
      <td>0.064516</td>
      <td>0.375</td>
      <td>0.293702</td>
      <td>0.375000</td>
    </tr>
    <tr>
      <th>f1-score</th>
      <td>0.196721</td>
      <td>0.536913</td>
      <td>0.086957</td>
      <td>0.375</td>
      <td>0.273530</td>
      <td>0.334918</td>
    </tr>
    <tr>
      <th>support</th>
      <td>35.000000</td>
      <td>62.000000</td>
      <td>31.000000</td>
      <td>0.375</td>
      <td>128.000000</td>
      <td>128.000000</td>
    </tr>
  </tbody>
</table>
</div>
<p><strong>Notice</strong> that another metric called <code>support</code> is included in the classification report. Support is simply the number of examples for each class.</p>
<p>We can save this full classification report to a file, for later indexing/reporting.</p>
<pre><code class="language-python">#save results to a file
confusion_matrix.to_csv('fileName.csv', index=True)
</code></pre>

    </div>

    





<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/data-projects/">Data Projects</a>
  
</div>



<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://nixramirez.github.io/project/classifier-diagnostics/&amp;text=Assessing%20Classification%20Models" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://nixramirez.github.io/project/classifier-diagnostics/&amp;t=Assessing%20Classification%20Models" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Assessing%20Classification%20Models&amp;body=https://nixramirez.github.io/project/classifier-diagnostics/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://nixramirez.github.io/project/classifier-diagnostics/&amp;title=Assessing%20Classification%20Models" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://web.whatsapp.com/send?text=Assessing%20Classification%20Models%20https://nixramirez.github.io/project/classifier-diagnostics/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https://nixramirez.github.io/project/classifier-diagnostics/&amp;title=Assessing%20Classification%20Models" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>












  






  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <img class="avatar mr-3 avatar-circle" src="/authors/admin/avatar_hu5b1350064ce29e3ab022863bed937806_1673660_270x270_fill_q90_lanczos_center.jpg" alt="Avatar">
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://nixramirez.github.io/">Nicole Ramirez</a></h5>
      <h6 class="card-subtitle">Master&rsquo;s Student, specialising in Data Analytics/Science</h6>
      <p class="card-text">Student and data enthusiast</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
    <li>
      <a href="mailto:nixramirez@gmail.com" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/nicole-ramirez-b11b54105/?originalSubdomain=nz" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/nxrmrz" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>









  
  
  <div class="article-widget content-widget-hr">
    <h3>Related</h3>
    <ul>
      
      <li><a href="/project/bert-emotion-classification/">Multi-Class Emotion Classification with Deep Learning using BERT</a></li>
      
      <li><a href="/project/data-scraping/">Web Scraping</a></li>
      
    </ul>
  </div>
  



    <div class="project-related-pages content-widget-hr">
      
      

      
      
      

      
      
      

      
      
      
    </div>
  </div>
</article>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js" integrity="sha256-1zu+3BnLYV9LdiY85uXMzii3bdrkelyp37e0ZyTAQh0=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/r.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.0630fec5958cb075a5a38f042b3ddde6.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
